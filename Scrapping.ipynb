{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1eb18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recherche pour お菓子: https://cookpad.com/jp/search/お菓子?order=recent\n",
      "Nombre d'articles chargés: 30\n"
     ]
    },
    {
     "ename": "InvalidSessionIdException",
     "evalue": "Message: invalid session id: session deleted as the browser has closed the connection\nfrom disconnected: not connected to DevTools\n  (Session info: chrome=136.0.7103.114)\nStacktrace:\n\tGetHandleVerifier [0x00007FF791AACF25+75717]\n\tGetHandleVerifier [0x00007FF791AACF80+75808]\n\t(No symbol) [0x00007FF791878F9A]\n\t(No symbol) [0x00007FF791864E35]\n\t(No symbol) [0x00007FF791889DB4]\n\t(No symbol) [0x00007FF7918FEE75]\n\t(No symbol) [0x00007FF79191ECC2]\n\t(No symbol) [0x00007FF7918F7153]\n\t(No symbol) [0x00007FF7918C0421]\n\t(No symbol) [0x00007FF7918C11B3]\n\tGetHandleVerifier [0x00007FF791DAD6FD+3223453]\n\tGetHandleVerifier [0x00007FF791DA7CA2+3200322]\n\tGetHandleVerifier [0x00007FF791DC5AD3+3322739]\n\tGetHandleVerifier [0x00007FF791AC69FA+180890]\n\tGetHandleVerifier [0x00007FF791ACE0FF+211359]\n\tGetHandleVerifier [0x00007FF791AB5274+109332]\n\tGetHandleVerifier [0x00007FF791AB5422+109762]\n\tGetHandleVerifier [0x00007FF791A9BA39+4825]\n\tBaseThreadInitThunk [0x00007FFD7A4F7374+20]\n\tRtlUserThreadStart [0x00007FFD7B19CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 154\u001b[0m\n\u001b[0;32m    152\u001b[0m prev_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    153\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     article_lis \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39;49mfind_elements(By\u001b[39m.\u001b[39;49mCSS_SELECTOR, \u001b[39m\"\u001b[39;49m\u001b[39mli[id^=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrecipe_\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    155\u001b[0m     current_count \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(article_lis)\n\u001b[0;32m    156\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNombre d\u001b[39m\u001b[39m'\u001b[39m\u001b[39marticles chargés: \u001b[39m\u001b[39m{\u001b[39;00mcurrent_count\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:955\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute_script(find_element_js, by\u001b[39m.\u001b[39mto_dict())\n\u001b[0;32m    953\u001b[0m \u001b[39m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[39m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 955\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENTS, {\u001b[39m\"\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m\"\u001b[39;49m: by, \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m []\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:448\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    446\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    447\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 448\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    449\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    230\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m: Message: invalid session id: session deleted as the browser has closed the connection\nfrom disconnected: not connected to DevTools\n  (Session info: chrome=136.0.7103.114)\nStacktrace:\n\tGetHandleVerifier [0x00007FF791AACF25+75717]\n\tGetHandleVerifier [0x00007FF791AACF80+75808]\n\t(No symbol) [0x00007FF791878F9A]\n\t(No symbol) [0x00007FF791864E35]\n\t(No symbol) [0x00007FF791889DB4]\n\t(No symbol) [0x00007FF7918FEE75]\n\t(No symbol) [0x00007FF79191ECC2]\n\t(No symbol) [0x00007FF7918F7153]\n\t(No symbol) [0x00007FF7918C0421]\n\t(No symbol) [0x00007FF7918C11B3]\n\tGetHandleVerifier [0x00007FF791DAD6FD+3223453]\n\tGetHandleVerifier [0x00007FF791DA7CA2+3200322]\n\tGetHandleVerifier [0x00007FF791DC5AD3+3322739]\n\tGetHandleVerifier [0x00007FF791AC69FA+180890]\n\tGetHandleVerifier [0x00007FF791ACE0FF+211359]\n\tGetHandleVerifier [0x00007FF791AB5274+109332]\n\tGetHandleVerifier [0x00007FF791AB5422+109762]\n\tGetHandleVerifier [0x00007FF791A9BA39+4825]\n\tBaseThreadInitThunk [0x00007FFD7A4F7374+20]\n\tRtlUserThreadStart [0x00007FFD7B19CC91+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# === CONFIGURATION DU TRAITEMENT D'IMAGES ===\n",
    "PHOTO_FOLDER = \"photos\"\n",
    "IMAGEKIT_PRIVATE_KEY = \"xxxxxx\"\n",
    "IMAGEKIT_URL_ENDPOINT = \"https://ik.imagekit.io/xxxxxx\"\n",
    "IMAGEKIT_UPLOAD_URL = \"https://upload.imagekit.io/api/v1/files/upload\"\n",
    "WATERMARK_TEXT = \"www.arabchefz.com\"\n",
    "FONT_SIZE = 30\n",
    "\n",
    "# Créer le dossier photos s'il n'existe pas\n",
    "os.makedirs(PHOTO_FOLDER, exist_ok=True)\n",
    "\n",
    "def is_processed(link):\n",
    "    return isinstance(link, str) and IMAGEKIT_URL_ENDPOINT in link\n",
    "\n",
    "def add_watermark(path, text, size=30):\n",
    "    try:\n",
    "        with Image.open(path).convert(\"RGBA\") as img:\n",
    "            txt = Image.new(\"RGBA\", img.size, (255,255,255,0))\n",
    "            draw = ImageDraw.Draw(txt)\n",
    "            try:\n",
    "                font = ImageFont.truetype(\"arial.ttf\", size)\n",
    "            except IOError:\n",
    "                font = ImageFont.load_default()\n",
    "            bbox = draw.textbbox((0,0), text, font=font)\n",
    "            x = (img.width - (bbox[2]-bbox[0]))/2\n",
    "            y = img.height - (bbox[3]-bbox[1]) - 10\n",
    "            draw.text((x,y), text, font=font, fill=(255,255,255,128))\n",
    "            combined = Image.alpha_composite(img, txt)\n",
    "            ext = os.path.splitext(path)[1].lower()\n",
    "            if ext==\".png\":\n",
    "                combined.save(path, \"PNG\")\n",
    "            else:\n",
    "                combined.convert(\"RGB\").save(path, \"JPEG\")\n",
    "        print(f\"✅ Watermark applied: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 Watermark error: {e}\")\n",
    "\n",
    "def compress_image(path, quality=40):\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            if img.mode in (\"RGBA\",\"P\"):\n",
    "                img = img.convert(\"RGB\")\n",
    "            img.save(path, optimize=True, quality=quality)\n",
    "        print(f\"✅ Compressed: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 Compression error: {e}\")\n",
    "\n",
    "def upload_to_imagekit(path):\n",
    "    try:\n",
    "        filename = os.path.basename(path)\n",
    "        # Basic auth: private key as username, blank password\n",
    "        auth = (IMAGEKIT_PRIVATE_KEY, \"\")\n",
    "        files = {\"file\": (filename, open(path, \"rb\"))}\n",
    "        data = {\"fileName\": filename, \"folder\": \"/\"}\n",
    "        resp = requests.post(IMAGEKIT_UPLOAD_URL, auth=auth, files=files, data=data, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        url = resp.json().get(\"url\")\n",
    "        if url:\n",
    "            print(f\"✅ Uploaded: {url}\")\n",
    "            return url\n",
    "        else:\n",
    "            print(f\"⚠️ No URL in response for {path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 Upload error: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_image_link(link, excel_path, idx):\n",
    "    if pd.isna(link) or is_processed(link):\n",
    "        return link if isinstance(link, str) else None\n",
    "    \n",
    "    base = os.path.splitext(os.path.basename(excel_path))[0]\n",
    "    local = os.path.join(PHOTO_FOLDER, f\"{base}_{idx}.jpg\")\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(link, timeout=20)\n",
    "        r.raise_for_status()\n",
    "        with open(local, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        compress_image(local)\n",
    "        add_watermark(local, WATERMARK_TEXT, FONT_SIZE)\n",
    "        return upload_to_imagekit(local)\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 Download error: {e}\")\n",
    "        return None\n",
    "\n",
    "# === SCRIPT ORIGINAL DE SCRAPING ===\n",
    "# Chemin vers le Chromedriver\n",
    "chromedriver_path = r'C:\\Users\\pc\\Desktop\\scrp\\chromedriver-win64\\chromedriver.exe'\n",
    "\n",
    "# Initialiser le driver avec Service\n",
    "service = Service(chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Chargement ou création du fichier scrape.json\n",
    "scraped_articles_file = \"scrape.json\"\n",
    "if os.path.exists(scraped_articles_file):\n",
    "    with open(scraped_articles_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        scraped_articles = json.load(f)\n",
    "else:\n",
    "    scraped_articles = []\n",
    "\n",
    "# Pour faciliter la vérification, créer un ensemble des IDs déjà visités\n",
    "visited_ids = {article.get(\"id\") for article in scraped_articles}\n",
    "\n",
    "# Liste des termes de recherche\n",
    "countries = [\"お菓子\" , \"パイ\"]\n",
    "\n",
    "# Fonction de nettoyage du nom de dossier/fichier\n",
    "def clean_filename(s):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \n",
    "        u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    s = emoji_pattern.sub(r'', s)\n",
    "    return \"\".join(c for c in s if c.isalnum() or c in (' ', '_')).rstrip()\n",
    "\n",
    "# Fonction pour sauvegarder immédiatement le fichier scrape.json\n",
    "def save_scraped_articles():\n",
    "    with open(scraped_articles_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(scraped_articles, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Pour chaque terme dans la liste, créer l'URL de recherche et extraire les recettes\n",
    "for country in countries:\n",
    "    search_url = f\"https://cookpad.com/jp/search/{country}?order=recent\"\n",
    "    print(f\"\\nRecherche pour {country}: {search_url}\")\n",
    "    driver.get(search_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Créer un dossier principal pour ce pays\n",
    "    country_folder = clean_filename(country)\n",
    "    if not os.path.exists(country_folder):\n",
    "        os.makedirs(country_folder)\n",
    "\n",
    "    # Nouvelle logique de scroll pour charger plus de recettes\n",
    "    desired_article_count = 100\n",
    "    prev_count = 0\n",
    "    while True:\n",
    "        article_lis = driver.find_elements(By.CSS_SELECTOR, \"li[id^='recipe_']\")\n",
    "        current_count = len(article_lis)\n",
    "        print(f\"Nombre d'articles chargés: {current_count}\")\n",
    "        if current_count >= desired_article_count:\n",
    "            break\n",
    "        if current_count == prev_count:\n",
    "            print(\"Aucun nouvel article détecté lors du défilement supplémentaire.\")\n",
    "            break\n",
    "        prev_count = current_count\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(15)\n",
    "\n",
    "    article_lis = driver.find_elements(By.CSS_SELECTOR, \"li[id^='recipe_']\")\n",
    "    articles = []\n",
    "    for li in article_lis:\n",
    "        try:\n",
    "            article_id = li.get_attribute(\"id\").replace(\"recipe_\", \"\")\n",
    "            link = li.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "            articles.append((article_id, link))\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la récupération du lien pour un article: {e}\")\n",
    "\n",
    "    print(f\"Nombre d'articles trouvés pour {country}: {len(articles)}\")\n",
    "\n",
    "    articles = articles[:100]  # Limiter le nombre d'articles à traiter\n",
    "\n",
    "    for article_id, article_link in articles:\n",
    "        # Vérifier si l'article a déjà été visité\n",
    "        if article_id in visited_ids:\n",
    "            print(f\"المقال ذو المعرف {article_id} قد تمت زيارته من قبل. يتم الانتقال للمقال التالي.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nTraitement de l'article {article_id} de {country}...\")\n",
    "        driver.get(article_link)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Extraction du titre\n",
    "        try:\n",
    "            title_elem = driver.find_element(By.TAG_NAME, \"h1\")\n",
    "            recipe_title = title_elem.text.strip()\n",
    "        except Exception as e:\n",
    "            recipe_title = \"Titre non trouvé\"\n",
    "        print(\"Titre:\", recipe_title)\n",
    "\n",
    "        # Extraction de l'image principale\n",
    "        try:\n",
    "            img_elem = driver.find_element(By.CSS_SELECTOR, \"img[fetchpriority='high']\")\n",
    "            img_url = img_elem.get_attribute(\"src\")\n",
    "        except Exception as e:\n",
    "            img_url = None\n",
    "        print(\"Image URL:\", img_url)\n",
    "\n",
    "        # Extraction des ingrédients\n",
    "        try:\n",
    "            ingredients_div = driver.find_element(By.CSS_SELECTOR, \"div.ingredient-list\")\n",
    "            ingredient_items = ingredients_div.find_elements(By.TAG_NAME, \"li\")\n",
    "            ingredients = [item.text.strip() for item in ingredient_items]\n",
    "        except Exception as e:\n",
    "            ingredients = []\n",
    "        print(\"Ingrédients:\", ingredients)\n",
    "\n",
    "        # Extraction des étapes\n",
    "        try:\n",
    "            steps_ol = driver.find_element(By.CSS_SELECTOR, \"ol.list-none\")\n",
    "            step_items = steps_ol.find_elements(By.TAG_NAME, \"li\")\n",
    "            steps = []\n",
    "            for li in step_items:\n",
    "                try:\n",
    "                    container = li.find_element(By.CSS_SELECTOR, \"div.w-full.grid.gap-sm.print\\\\:grid-flow-col\")\n",
    "                    children = container.find_elements(By.XPATH, \"./*\")\n",
    "                    for child in children:\n",
    "                        p_elems = child.find_elements(By.TAG_NAME, \"p\")\n",
    "                        if p_elems:\n",
    "                            text = p_elems[0].text.strip()\n",
    "                            if text:\n",
    "                                steps.append(text)\n",
    "                        a_elems = child.find_elements(By.TAG_NAME, \"a\")\n",
    "                        for a in a_elems:\n",
    "                            try:\n",
    "                                picture = a.find_element(By.TAG_NAME, \"picture\")\n",
    "                                img = picture.find_element(By.TAG_NAME, \"img\")\n",
    "                                img_src = img.get_attribute(\"src\")\n",
    "                                if img_src:\n",
    "                                    steps.append(img_src)\n",
    "                            except Exception as e_img:\n",
    "                                href = a.get_attribute(\"href\")\n",
    "                                if href:\n",
    "                                    steps.append(href)\n",
    "                except Exception as e:\n",
    "                    p_elems = li.find_elements(By.TAG_NAME, \"p\")\n",
    "                    if p_elems:\n",
    "                        text = p_elems[0].text.strip()\n",
    "                        if text:\n",
    "                            steps.append(text)\n",
    "        except Exception as e:\n",
    "            steps = []\n",
    "        print(\"Étapes (texte et images):\", steps)\n",
    "\n",
    "        # Vérification des conditions\n",
    "        condition_met = False\n",
    "\n",
    "        # Condition 1 : \"ينوون تحضير\" avec un nombre ≥ 25\n",
    "        try:\n",
    "            intent_elem = driver.find_element(By.XPATH, \"//span[contains(text(), 'ينوون تحضير')]\")\n",
    "            intent_text = intent_elem.text.strip()\n",
    "            m = re.search(r\"(\\d+)\", intent_text)\n",
    "            if m:\n",
    "                intent_count = int(m.group(1))\n",
    "                if intent_count >= 1:\n",
    "                    condition_met = True\n",
    "                    print(\"شرط 1 تحقق: يوجد {} كوكباديين ينوون تحضير الوصفة.\".format(intent_count))\n",
    "            else:\n",
    "                print(\"لم يتم العثور على رقم في شرط 'ينوون تحضير'.\")\n",
    "        except Exception as e:\n",
    "            print(\"شرط 1 غير متوفر:\", e)\n",
    "\n",
    "        # Condition 2 : إذا لم يتحقق الشرط الأول، التحقق من وجود ≥ 25 تعليقات\n",
    "        if not condition_met:\n",
    "            try:\n",
    "                comments_elem = driver.find_element(By.XPATH, \"//span[contains(text(), 'تعليقات')]\")\n",
    "                comments_text = comments_elem.text.strip()\n",
    "                m = re.search(r\"(\\d+)\", comments_text)\n",
    "                if m:\n",
    "                    comments_count = int(m.group(1))\n",
    "                    if comments_count >= 1:\n",
    "                        condition_met = True\n",
    "                        print(\"شرط 2 تحقق: يوجد {} تعليق.\".format(comments_count))\n",
    "                else:\n",
    "                    print(\"لم يتم العثور على رقم في شرط 'تعليقات'.\")\n",
    "            except Exception as e:\n",
    "                print(\"شرط 2 غير متوفر:\", e)\n",
    "\n",
    "        # Condition 3 : إذا لم يتحقق أي من الشرطين précédent, التحقق من وجود ≥ 30 تفاعلات\n",
    "        if not condition_met:\n",
    "            try:\n",
    "                reactions_ul = driver.find_element(By.CSS_SELECTOR, \"ul[data-controller='reactions']\")\n",
    "                reaction_items = reactions_ul.find_elements(By.CSS_SELECTOR, \"li.reaction\")\n",
    "                total_reactions = 0\n",
    "                for item in reaction_items:\n",
    "                    try:\n",
    "                        count_elem = item.find_element(By.CSS_SELECTOR, \"span[data-reactions-target='count']\")\n",
    "                        count = int(count_elem.text.strip())\n",
    "                        total_reactions += count\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                if total_reactions >= 0:\n",
    "                    condition_met = True\n",
    "                    print(\"شرط 3 تحقق: مجموع التفاعلات هو {}.\".format(total_reactions))\n",
    "                else:\n",
    "                    print(\"مجموع التفاعلات أقل من المطلوب.\")\n",
    "            except Exception as e:\n",
    "                print(\"شرط 3 غير متوفر:\", e)\n",
    "\n",
    "        # Créer le record pour l'article visité\n",
    "        record = {\n",
    "            \"id\": article_id,\n",
    "            \"titre\": recipe_title,\n",
    "            \"lien\": article_link,\n",
    "            \"excel\": None,\n",
    "            \"raison\": \"\"\n",
    "        }\n",
    "\n",
    "        if condition_met:\n",
    "            # Préparation et sauvegarde dans un fichier Excel\n",
    "            max_len = max(len(ingredients), len(steps))\n",
    "            if len(ingredients) < max_len:\n",
    "                ingredients.extend([None] * (max_len - len(ingredients)))\n",
    "            if len(steps) < max_len:\n",
    "                steps.extend([None] * (max_len - len(steps)))\n",
    "\n",
    "            data_rows = []\n",
    "            for i in range(max_len):\n",
    "                data_rows.append({\n",
    "                    \"titre\": None,\n",
    "                    \"ingrédient\": ingredients[i],\n",
    "                    \"étape\": steps[i],\n",
    "                    \"img_link\": None\n",
    "                })\n",
    "            df_rows = pd.DataFrame(data_rows)\n",
    "\n",
    "            # Extraction du temps de préparation avec un sélecteur CSS plus précis\n",
    "            try:\n",
    "                time_elem = driver.find_element(By.CSS_SELECTOR, \"div.max-lg\\\\:hidden.print\\\\:block.text-cookpad-gray-600.text-cookpad-14.mb-rg span.mise-icon-text\")\n",
    "                preparation_time = time_elem.text.strip()\n",
    "            except Exception as e:\n",
    "                preparation_time = None\n",
    "            print(\"Temps de préparation:\", preparation_time)\n",
    "\n",
    "            # Ajout du temps de préparation dans le DataFrame\n",
    "            top_row = pd.DataFrame([{\n",
    "                \"titre\": recipe_title,\n",
    "                \"temps\": preparation_time,  # Nouvelle colonne\n",
    "                \"ingrédient\": None,\n",
    "                \"étape\": None,\n",
    "                \"img_link\": img_url\n",
    "            }])\n",
    "            final_df = pd.concat([top_row, df_rows], ignore_index=True)\n",
    "\n",
    "            excel_file_name = clean_filename(recipe_title) + \".xlsx\"\n",
    "            excel_path = os.path.join(country_folder, excel_file_name)\n",
    "\n",
    "            # === TRAITEMENT DES IMAGES ===\n",
    "            new_links = []\n",
    "            for idx, row in final_df.iterrows():\n",
    "                link = row['img_link']\n",
    "                if pd.isna(link) or is_processed(link):\n",
    "                    new_links.append(link if isinstance(link, str) else None)\n",
    "                    continue\n",
    "                \n",
    "                processed_link = process_image_link(link, excel_path, idx)\n",
    "                new_links.append(processed_link)\n",
    "            \n",
    "            final_df['img_link'] = new_links\n",
    "\n",
    "            # Sauvegarde du fichier Excel\n",
    "            writer = pd.ExcelWriter(excel_path, engine='xlsxwriter')\n",
    "            final_df.to_excel(writer, index=False, sheet_name='Recette')\n",
    "\n",
    "            workbook  = writer.book\n",
    "            worksheet = writer.sheets['Recette']\n",
    "            wrap_format = workbook.add_format({'text_wrap': True})\n",
    "            worksheet.set_column('C:C', 40, wrap_format)\n",
    "            writer.close()\n",
    "\n",
    "            print(\"Données sauvegardées dans :\", excel_path)\n",
    "            record[\"excel\"] = excel_path\n",
    "            record[\"raison\"] = \"conditions remplies et données extraites\"\n",
    "        else:\n",
    "            print(\"Les conditions ne sont pas remplies, la recette ne sera pas sauvegardée en Excel.\")\n",
    "            record[\"raison\"] = \"visité mais conditions non remplies\"\n",
    "\n",
    "        # Ajouter l'article à la liste et à l'ensemble visited_ids\n",
    "        scraped_articles.append(record)\n",
    "        visited_ids.add(article_id)\n",
    "\n",
    "        # Sauvegarder immédiatement le fichier après le traitement de chaque article\n",
    "        save_scraped_articles()\n",
    "\n",
    "        time.sleep(3)\n",
    "driver.quit()\n",
    "print(\"Extraction terminée.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
