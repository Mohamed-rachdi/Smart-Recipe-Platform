{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c1eb18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recherche pour ãŠè“å­: https://cookpad.com/jp/search/ãŠè“å­?order=recent\n",
      "Nombre d'articles chargÃ©s: 30\n"
     ]
    },
    {
     "ename": "InvalidSessionIdException",
     "evalue": "Message: invalid session id: session deleted as the browser has closed the connection\nfrom disconnected: not connected to DevTools\n  (Session info: chrome=136.0.7103.114)\nStacktrace:\n\tGetHandleVerifier [0x00007FF791AACF25+75717]\n\tGetHandleVerifier [0x00007FF791AACF80+75808]\n\t(No symbol) [0x00007FF791878F9A]\n\t(No symbol) [0x00007FF791864E35]\n\t(No symbol) [0x00007FF791889DB4]\n\t(No symbol) [0x00007FF7918FEE75]\n\t(No symbol) [0x00007FF79191ECC2]\n\t(No symbol) [0x00007FF7918F7153]\n\t(No symbol) [0x00007FF7918C0421]\n\t(No symbol) [0x00007FF7918C11B3]\n\tGetHandleVerifier [0x00007FF791DAD6FD+3223453]\n\tGetHandleVerifier [0x00007FF791DA7CA2+3200322]\n\tGetHandleVerifier [0x00007FF791DC5AD3+3322739]\n\tGetHandleVerifier [0x00007FF791AC69FA+180890]\n\tGetHandleVerifier [0x00007FF791ACE0FF+211359]\n\tGetHandleVerifier [0x00007FF791AB5274+109332]\n\tGetHandleVerifier [0x00007FF791AB5422+109762]\n\tGetHandleVerifier [0x00007FF791A9BA39+4825]\n\tBaseThreadInitThunk [0x00007FFD7A4F7374+20]\n\tRtlUserThreadStart [0x00007FFD7B19CC91+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 154\u001b[0m\n\u001b[0;32m    152\u001b[0m prev_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    153\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     article_lis \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39;49mfind_elements(By\u001b[39m.\u001b[39;49mCSS_SELECTOR, \u001b[39m\"\u001b[39;49m\u001b[39mli[id^=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrecipe_\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    155\u001b[0m     current_count \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(article_lis)\n\u001b[0;32m    156\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNombre d\u001b[39m\u001b[39m'\u001b[39m\u001b[39marticles chargÃ©s: \u001b[39m\u001b[39m{\u001b[39;00mcurrent_count\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:955\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    951\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute_script(find_element_js, by\u001b[39m.\u001b[39mto_dict())\n\u001b[0;32m    953\u001b[0m \u001b[39m# Return empty list if driver returns null\u001b[39;00m\n\u001b[0;32m    954\u001b[0m \u001b[39m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[1;32m--> 955\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENTS, {\u001b[39m\"\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m\"\u001b[39;49m: by, \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m []\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:448\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    446\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    447\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 448\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    449\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    230\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mInvalidSessionIdException\u001b[0m: Message: invalid session id: session deleted as the browser has closed the connection\nfrom disconnected: not connected to DevTools\n  (Session info: chrome=136.0.7103.114)\nStacktrace:\n\tGetHandleVerifier [0x00007FF791AACF25+75717]\n\tGetHandleVerifier [0x00007FF791AACF80+75808]\n\t(No symbol) [0x00007FF791878F9A]\n\t(No symbol) [0x00007FF791864E35]\n\t(No symbol) [0x00007FF791889DB4]\n\t(No symbol) [0x00007FF7918FEE75]\n\t(No symbol) [0x00007FF79191ECC2]\n\t(No symbol) [0x00007FF7918F7153]\n\t(No symbol) [0x00007FF7918C0421]\n\t(No symbol) [0x00007FF7918C11B3]\n\tGetHandleVerifier [0x00007FF791DAD6FD+3223453]\n\tGetHandleVerifier [0x00007FF791DA7CA2+3200322]\n\tGetHandleVerifier [0x00007FF791DC5AD3+3322739]\n\tGetHandleVerifier [0x00007FF791AC69FA+180890]\n\tGetHandleVerifier [0x00007FF791ACE0FF+211359]\n\tGetHandleVerifier [0x00007FF791AB5274+109332]\n\tGetHandleVerifier [0x00007FF791AB5422+109762]\n\tGetHandleVerifier [0x00007FF791A9BA39+4825]\n\tBaseThreadInitThunk [0x00007FFD7A4F7374+20]\n\tRtlUserThreadStart [0x00007FFD7B19CC91+33]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# === CONFIGURATION DU TRAITEMENT D'IMAGES ===\n",
    "PHOTO_FOLDER = \"photos\"\n",
    "IMAGEKIT_PRIVATE_KEY = \"xxxxxx\"\n",
    "IMAGEKIT_URL_ENDPOINT = \"https://ik.imagekit.io/xxxxxx\"\n",
    "IMAGEKIT_UPLOAD_URL = \"https://upload.imagekit.io/api/v1/files/upload\"\n",
    "WATERMARK_TEXT = \"www.arabchefz.com\"\n",
    "FONT_SIZE = 30\n",
    "\n",
    "# CrÃ©er le dossier photos s'il n'existe pas\n",
    "os.makedirs(PHOTO_FOLDER, exist_ok=True)\n",
    "\n",
    "def is_processed(link):\n",
    "    return isinstance(link, str) and IMAGEKIT_URL_ENDPOINT in link\n",
    "\n",
    "def add_watermark(path, text, size=30):\n",
    "    try:\n",
    "        with Image.open(path).convert(\"RGBA\") as img:\n",
    "            txt = Image.new(\"RGBA\", img.size, (255,255,255,0))\n",
    "            draw = ImageDraw.Draw(txt)\n",
    "            try:\n",
    "                font = ImageFont.truetype(\"arial.ttf\", size)\n",
    "            except IOError:\n",
    "                font = ImageFont.load_default()\n",
    "            bbox = draw.textbbox((0,0), text, font=font)\n",
    "            x = (img.width - (bbox[2]-bbox[0]))/2\n",
    "            y = img.height - (bbox[3]-bbox[1]) - 10\n",
    "            draw.text((x,y), text, font=font, fill=(255,255,255,128))\n",
    "            combined = Image.alpha_composite(img, txt)\n",
    "            ext = os.path.splitext(path)[1].lower()\n",
    "            if ext==\".png\":\n",
    "                combined.save(path, \"PNG\")\n",
    "            else:\n",
    "                combined.convert(\"RGB\").save(path, \"JPEG\")\n",
    "        print(f\"âœ… Watermark applied: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Watermark error: {e}\")\n",
    "\n",
    "def compress_image(path, quality=40):\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            if img.mode in (\"RGBA\",\"P\"):\n",
    "                img = img.convert(\"RGB\")\n",
    "            img.save(path, optimize=True, quality=quality)\n",
    "        print(f\"âœ… Compressed: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Compression error: {e}\")\n",
    "\n",
    "def upload_to_imagekit(path):\n",
    "    try:\n",
    "        filename = os.path.basename(path)\n",
    "        # Basic auth: private key as username, blank password\n",
    "        auth = (IMAGEKIT_PRIVATE_KEY, \"\")\n",
    "        files = {\"file\": (filename, open(path, \"rb\"))}\n",
    "        data = {\"fileName\": filename, \"folder\": \"/\"}\n",
    "        resp = requests.post(IMAGEKIT_UPLOAD_URL, auth=auth, files=files, data=data, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        url = resp.json().get(\"url\")\n",
    "        if url:\n",
    "            print(f\"âœ… Uploaded: {url}\")\n",
    "            return url\n",
    "        else:\n",
    "            print(f\"âš ï¸ No URL in response for {path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Upload error: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_image_link(link, excel_path, idx):\n",
    "    if pd.isna(link) or is_processed(link):\n",
    "        return link if isinstance(link, str) else None\n",
    "    \n",
    "    base = os.path.splitext(os.path.basename(excel_path))[0]\n",
    "    local = os.path.join(PHOTO_FOLDER, f\"{base}_{idx}.jpg\")\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(link, timeout=20)\n",
    "        r.raise_for_status()\n",
    "        with open(local, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        compress_image(local)\n",
    "        add_watermark(local, WATERMARK_TEXT, FONT_SIZE)\n",
    "        return upload_to_imagekit(local)\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Download error: {e}\")\n",
    "        return None\n",
    "\n",
    "# === SCRIPT ORIGINAL DE SCRAPING ===\n",
    "# Chemin vers le Chromedriver\n",
    "chromedriver_path = r'C:\\Users\\pc\\Desktop\\scrp\\chromedriver-win64\\chromedriver.exe'\n",
    "\n",
    "# Initialiser le driver avec Service\n",
    "service = Service(chromedriver_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Chargement ou crÃ©ation du fichier scrape.json\n",
    "scraped_articles_file = \"scrape.json\"\n",
    "if os.path.exists(scraped_articles_file):\n",
    "    with open(scraped_articles_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        scraped_articles = json.load(f)\n",
    "else:\n",
    "    scraped_articles = []\n",
    "\n",
    "# Pour faciliter la vÃ©rification, crÃ©er un ensemble des IDs dÃ©jÃ  visitÃ©s\n",
    "visited_ids = {article.get(\"id\") for article in scraped_articles}\n",
    "\n",
    "# Liste des termes de recherche\n",
    "countries = [\"ãŠè“å­\" , \"ãƒ‘ã‚¤\"]\n",
    "\n",
    "# Fonction de nettoyage du nom de dossier/fichier\n",
    "def clean_filename(s):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \n",
    "        u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # Flags\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    s = emoji_pattern.sub(r'', s)\n",
    "    return \"\".join(c for c in s if c.isalnum() or c in (' ', '_')).rstrip()\n",
    "\n",
    "# Fonction pour sauvegarder immÃ©diatement le fichier scrape.json\n",
    "def save_scraped_articles():\n",
    "    with open(scraped_articles_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(scraped_articles, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Pour chaque terme dans la liste, crÃ©er l'URL de recherche et extraire les recettes\n",
    "for country in countries:\n",
    "    search_url = f\"https://cookpad.com/jp/search/{country}?order=recent\"\n",
    "    print(f\"\\nRecherche pour {country}: {search_url}\")\n",
    "    driver.get(search_url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # CrÃ©er un dossier principal pour ce pays\n",
    "    country_folder = clean_filename(country)\n",
    "    if not os.path.exists(country_folder):\n",
    "        os.makedirs(country_folder)\n",
    "\n",
    "    # Nouvelle logique de scroll pour charger plus de recettes\n",
    "    desired_article_count = 100\n",
    "    prev_count = 0\n",
    "    while True:\n",
    "        article_lis = driver.find_elements(By.CSS_SELECTOR, \"li[id^='recipe_']\")\n",
    "        current_count = len(article_lis)\n",
    "        print(f\"Nombre d'articles chargÃ©s: {current_count}\")\n",
    "        if current_count >= desired_article_count:\n",
    "            break\n",
    "        if current_count == prev_count:\n",
    "            print(\"Aucun nouvel article dÃ©tectÃ© lors du dÃ©filement supplÃ©mentaire.\")\n",
    "            break\n",
    "        prev_count = current_count\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(15)\n",
    "\n",
    "    article_lis = driver.find_elements(By.CSS_SELECTOR, \"li[id^='recipe_']\")\n",
    "    articles = []\n",
    "    for li in article_lis:\n",
    "        try:\n",
    "            article_id = li.get_attribute(\"id\").replace(\"recipe_\", \"\")\n",
    "            link = li.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\")\n",
    "            articles.append((article_id, link))\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la rÃ©cupÃ©ration du lien pour un article: {e}\")\n",
    "\n",
    "    print(f\"Nombre d'articles trouvÃ©s pour {country}: {len(articles)}\")\n",
    "\n",
    "    articles = articles[:100]  # Limiter le nombre d'articles Ã  traiter\n",
    "\n",
    "    for article_id, article_link in articles:\n",
    "        # VÃ©rifier si l'article a dÃ©jÃ  Ã©tÃ© visitÃ©\n",
    "        if article_id in visited_ids:\n",
    "            print(f\"Ø§Ù„Ù…Ù‚Ø§Ù„ Ø°Ùˆ Ø§Ù„Ù…Ø¹Ø±Ù {article_id} Ù‚Ø¯ ØªÙ…Øª Ø²ÙŠØ§Ø±ØªÙ‡ Ù…Ù† Ù‚Ø¨Ù„. ÙŠØªÙ… Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„Ù…Ù‚Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nTraitement de l'article {article_id} de {country}...\")\n",
    "        driver.get(article_link)\n",
    "        time.sleep(3)\n",
    "\n",
    "        # Extraction du titre\n",
    "        try:\n",
    "            title_elem = driver.find_element(By.TAG_NAME, \"h1\")\n",
    "            recipe_title = title_elem.text.strip()\n",
    "        except Exception as e:\n",
    "            recipe_title = \"Titre non trouvÃ©\"\n",
    "        print(\"Titre:\", recipe_title)\n",
    "\n",
    "        # Extraction de l'image principale\n",
    "        try:\n",
    "            img_elem = driver.find_element(By.CSS_SELECTOR, \"img[fetchpriority='high']\")\n",
    "            img_url = img_elem.get_attribute(\"src\")\n",
    "        except Exception as e:\n",
    "            img_url = None\n",
    "        print(\"Image URL:\", img_url)\n",
    "\n",
    "        # Extraction des ingrÃ©dients\n",
    "        try:\n",
    "            ingredients_div = driver.find_element(By.CSS_SELECTOR, \"div.ingredient-list\")\n",
    "            ingredient_items = ingredients_div.find_elements(By.TAG_NAME, \"li\")\n",
    "            ingredients = [item.text.strip() for item in ingredient_items]\n",
    "        except Exception as e:\n",
    "            ingredients = []\n",
    "        print(\"IngrÃ©dients:\", ingredients)\n",
    "\n",
    "        # Extraction des Ã©tapes\n",
    "        try:\n",
    "            steps_ol = driver.find_element(By.CSS_SELECTOR, \"ol.list-none\")\n",
    "            step_items = steps_ol.find_elements(By.TAG_NAME, \"li\")\n",
    "            steps = []\n",
    "            for li in step_items:\n",
    "                try:\n",
    "                    container = li.find_element(By.CSS_SELECTOR, \"div.w-full.grid.gap-sm.print\\\\:grid-flow-col\")\n",
    "                    children = container.find_elements(By.XPATH, \"./*\")\n",
    "                    for child in children:\n",
    "                        p_elems = child.find_elements(By.TAG_NAME, \"p\")\n",
    "                        if p_elems:\n",
    "                            text = p_elems[0].text.strip()\n",
    "                            if text:\n",
    "                                steps.append(text)\n",
    "                        a_elems = child.find_elements(By.TAG_NAME, \"a\")\n",
    "                        for a in a_elems:\n",
    "                            try:\n",
    "                                picture = a.find_element(By.TAG_NAME, \"picture\")\n",
    "                                img = picture.find_element(By.TAG_NAME, \"img\")\n",
    "                                img_src = img.get_attribute(\"src\")\n",
    "                                if img_src:\n",
    "                                    steps.append(img_src)\n",
    "                            except Exception as e_img:\n",
    "                                href = a.get_attribute(\"href\")\n",
    "                                if href:\n",
    "                                    steps.append(href)\n",
    "                except Exception as e:\n",
    "                    p_elems = li.find_elements(By.TAG_NAME, \"p\")\n",
    "                    if p_elems:\n",
    "                        text = p_elems[0].text.strip()\n",
    "                        if text:\n",
    "                            steps.append(text)\n",
    "        except Exception as e:\n",
    "            steps = []\n",
    "        print(\"Ã‰tapes (texte et images):\", steps)\n",
    "\n",
    "        # VÃ©rification des conditions\n",
    "        condition_met = False\n",
    "\n",
    "        # Condition 1 : \"ÙŠÙ†ÙˆÙˆÙ† ØªØ­Ø¶ÙŠØ±\" avec un nombre â‰¥ 25\n",
    "        try:\n",
    "            intent_elem = driver.find_element(By.XPATH, \"//span[contains(text(), 'ÙŠÙ†ÙˆÙˆÙ† ØªØ­Ø¶ÙŠØ±')]\")\n",
    "            intent_text = intent_elem.text.strip()\n",
    "            m = re.search(r\"(\\d+)\", intent_text)\n",
    "            if m:\n",
    "                intent_count = int(m.group(1))\n",
    "                if intent_count >= 1:\n",
    "                    condition_met = True\n",
    "                    print(\"Ø´Ø±Ø· 1 ØªØ­Ù‚Ù‚: ÙŠÙˆØ¬Ø¯ {} ÙƒÙˆÙƒØ¨Ø§Ø¯ÙŠÙŠÙ† ÙŠÙ†ÙˆÙˆÙ† ØªØ­Ø¶ÙŠØ± Ø§Ù„ÙˆØµÙØ©.\".format(intent_count))\n",
    "            else:\n",
    "                print(\"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ù‚Ù… ÙÙŠ Ø´Ø±Ø· 'ÙŠÙ†ÙˆÙˆÙ† ØªØ­Ø¶ÙŠØ±'.\")\n",
    "        except Exception as e:\n",
    "            print(\"Ø´Ø±Ø· 1 ØºÙŠØ± Ù…ØªÙˆÙØ±:\", e)\n",
    "\n",
    "        # Condition 2 : Ø¥Ø°Ø§ Ù„Ù… ÙŠØªØ­Ù‚Ù‚ Ø§Ù„Ø´Ø±Ø· Ø§Ù„Ø£ÙˆÙ„ØŒ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ â‰¥ 25 ØªØ¹Ù„ÙŠÙ‚Ø§Øª\n",
    "        if not condition_met:\n",
    "            try:\n",
    "                comments_elem = driver.find_element(By.XPATH, \"//span[contains(text(), 'ØªØ¹Ù„ÙŠÙ‚Ø§Øª')]\")\n",
    "                comments_text = comments_elem.text.strip()\n",
    "                m = re.search(r\"(\\d+)\", comments_text)\n",
    "                if m:\n",
    "                    comments_count = int(m.group(1))\n",
    "                    if comments_count >= 1:\n",
    "                        condition_met = True\n",
    "                        print(\"Ø´Ø±Ø· 2 ØªØ­Ù‚Ù‚: ÙŠÙˆØ¬Ø¯ {} ØªØ¹Ù„ÙŠÙ‚.\".format(comments_count))\n",
    "                else:\n",
    "                    print(\"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ù‚Ù… ÙÙŠ Ø´Ø±Ø· 'ØªØ¹Ù„ÙŠÙ‚Ø§Øª'.\")\n",
    "            except Exception as e:\n",
    "                print(\"Ø´Ø±Ø· 2 ØºÙŠØ± Ù…ØªÙˆÙØ±:\", e)\n",
    "\n",
    "        # Condition 3 : Ø¥Ø°Ø§ Ù„Ù… ÙŠØªØ­Ù‚Ù‚ Ø£ÙŠ Ù…Ù† Ø§Ù„Ø´Ø±Ø·ÙŠÙ† prÃ©cÃ©dent, Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ â‰¥ 30 ØªÙØ§Ø¹Ù„Ø§Øª\n",
    "        if not condition_met:\n",
    "            try:\n",
    "                reactions_ul = driver.find_element(By.CSS_SELECTOR, \"ul[data-controller='reactions']\")\n",
    "                reaction_items = reactions_ul.find_elements(By.CSS_SELECTOR, \"li.reaction\")\n",
    "                total_reactions = 0\n",
    "                for item in reaction_items:\n",
    "                    try:\n",
    "                        count_elem = item.find_element(By.CSS_SELECTOR, \"span[data-reactions-target='count']\")\n",
    "                        count = int(count_elem.text.strip())\n",
    "                        total_reactions += count\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                if total_reactions >= 0:\n",
    "                    condition_met = True\n",
    "                    print(\"Ø´Ø±Ø· 3 ØªØ­Ù‚Ù‚: Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ù‡Ùˆ {}.\".format(total_reactions))\n",
    "                else:\n",
    "                    print(\"Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ù…Ø·Ù„ÙˆØ¨.\")\n",
    "            except Exception as e:\n",
    "                print(\"Ø´Ø±Ø· 3 ØºÙŠØ± Ù…ØªÙˆÙØ±:\", e)\n",
    "\n",
    "        # CrÃ©er le record pour l'article visitÃ©\n",
    "        record = {\n",
    "            \"id\": article_id,\n",
    "            \"titre\": recipe_title,\n",
    "            \"lien\": article_link,\n",
    "            \"excel\": None,\n",
    "            \"raison\": \"\"\n",
    "        }\n",
    "\n",
    "        if condition_met:\n",
    "            # PrÃ©paration et sauvegarde dans un fichier Excel\n",
    "            max_len = max(len(ingredients), len(steps))\n",
    "            if len(ingredients) < max_len:\n",
    "                ingredients.extend([None] * (max_len - len(ingredients)))\n",
    "            if len(steps) < max_len:\n",
    "                steps.extend([None] * (max_len - len(steps)))\n",
    "\n",
    "            data_rows = []\n",
    "            for i in range(max_len):\n",
    "                data_rows.append({\n",
    "                    \"titre\": None,\n",
    "                    \"ingrÃ©dient\": ingredients[i],\n",
    "                    \"Ã©tape\": steps[i],\n",
    "                    \"img_link\": None\n",
    "                })\n",
    "            df_rows = pd.DataFrame(data_rows)\n",
    "\n",
    "            # Extraction du temps de prÃ©paration avec un sÃ©lecteur CSS plus prÃ©cis\n",
    "            try:\n",
    "                time_elem = driver.find_element(By.CSS_SELECTOR, \"div.max-lg\\\\:hidden.print\\\\:block.text-cookpad-gray-600.text-cookpad-14.mb-rg span.mise-icon-text\")\n",
    "                preparation_time = time_elem.text.strip()\n",
    "            except Exception as e:\n",
    "                preparation_time = None\n",
    "            print(\"Temps de prÃ©paration:\", preparation_time)\n",
    "\n",
    "            # Ajout du temps de prÃ©paration dans le DataFrame\n",
    "            top_row = pd.DataFrame([{\n",
    "                \"titre\": recipe_title,\n",
    "                \"temps\": preparation_time,  # Nouvelle colonne\n",
    "                \"ingrÃ©dient\": None,\n",
    "                \"Ã©tape\": None,\n",
    "                \"img_link\": img_url\n",
    "            }])\n",
    "            final_df = pd.concat([top_row, df_rows], ignore_index=True)\n",
    "\n",
    "            excel_file_name = clean_filename(recipe_title) + \".xlsx\"\n",
    "            excel_path = os.path.join(country_folder, excel_file_name)\n",
    "\n",
    "            # === TRAITEMENT DES IMAGES ===\n",
    "            new_links = []\n",
    "            for idx, row in final_df.iterrows():\n",
    "                link = row['img_link']\n",
    "                if pd.isna(link) or is_processed(link):\n",
    "                    new_links.append(link if isinstance(link, str) else None)\n",
    "                    continue\n",
    "                \n",
    "                processed_link = process_image_link(link, excel_path, idx)\n",
    "                new_links.append(processed_link)\n",
    "            \n",
    "            final_df['img_link'] = new_links\n",
    "\n",
    "            # Sauvegarde du fichier Excel\n",
    "            writer = pd.ExcelWriter(excel_path, engine='xlsxwriter')\n",
    "            final_df.to_excel(writer, index=False, sheet_name='Recette')\n",
    "\n",
    "            workbook  = writer.book\n",
    "            worksheet = writer.sheets['Recette']\n",
    "            wrap_format = workbook.add_format({'text_wrap': True})\n",
    "            worksheet.set_column('C:C', 40, wrap_format)\n",
    "            writer.close()\n",
    "\n",
    "            print(\"DonnÃ©es sauvegardÃ©es dans :\", excel_path)\n",
    "            record[\"excel\"] = excel_path\n",
    "            record[\"raison\"] = \"conditions remplies et donnÃ©es extraites\"\n",
    "        else:\n",
    "            print(\"Les conditions ne sont pas remplies, la recette ne sera pas sauvegardÃ©e en Excel.\")\n",
    "            record[\"raison\"] = \"visitÃ© mais conditions non remplies\"\n",
    "\n",
    "        # Ajouter l'article Ã  la liste et Ã  l'ensemble visited_ids\n",
    "        scraped_articles.append(record)\n",
    "        visited_ids.add(article_id)\n",
    "\n",
    "        # Sauvegarder immÃ©diatement le fichier aprÃ¨s le traitement de chaque article\n",
    "        save_scraped_articles()\n",
    "\n",
    "        time.sleep(3)\n",
    "driver.quit()\n",
    "print(\"Extraction terminÃ©e.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
